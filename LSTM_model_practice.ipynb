{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzArpdadUMrVwEx/lNdqC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diggibyte/dsplayground/blob/main/LSTM_model_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBnymtM9LC0",
        "outputId": "edca8200-b639-4446-ff59-fca96e2865e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten "
      ],
      "metadata": {
        "id": "gluxV7fu9ooX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing independent and dependent features\n",
        "def prepare_data(timeseries_data, n_features):\n",
        "  X,y = [],[]\n",
        "  for i in range(len(timeseries_data)):\n",
        "    #find the end of this pattern\n",
        "    end_ix =i + n_features\n",
        "    #check if we are beyond the sequence\n",
        "    if end_ix > len(timeseries_data)-1:\n",
        "      break\n",
        "    #gather input and output parts of the pattern\n",
        "    seq_x,seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return np.array(X), np.array(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "ufTYZQxW9v0l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define input sequence\n",
        "timeseries_data = [110,125,133,146,158,172,187,196,210]\n",
        "#choose number of time steps\n",
        "n_steps = 3\n",
        "#split into samples\n",
        "X,y = prepare_data(timeseries_data, n_steps)\n"
      ],
      "metadata": {
        "id": "ZwOl_1K1I5kt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X),print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxafR6dxJ400",
        "outputId": "05e73027-d5d9-41df-b63d-7e402f213cd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[110 125 133]\n",
            " [125 133 146]\n",
            " [133 146 158]\n",
            " [146 158 172]\n",
            " [158 172 187]\n",
            " [172 187 196]]\n",
            "[146 158 172 187 196 210]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reshape from [samples,timesteps] to [samples,timesteps, features]\n",
        "n_features= 1\n",
        "X = X.reshape((X.shape[0],X.shape[1],n_features))"
      ],
      "metadata": {
        "id": "WcTILZizKWnJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building LSTM Model\n"
      ],
      "metadata": {
        "id": "WcHpoJaJKzM5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation = 'relu', return_sequences = True, input_shape =(n_steps, n_features)))\n",
        "model.add(LSTM(50,activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer ='adam',loss ='mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlE8YzrOK9Zi",
        "outputId": "973ea3cd-5a4f-4a57-ac0f-d0d36d557e34"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit model\n",
        "model.fit(X,y, epochs = 300, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_CPoPpCMFFJ",
        "outputId": "8cb07ebc-8a4d-410c-9904-1c6e018752d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 5s 5s/step - loss: 32124.9688\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 31818.8906\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 31496.5469\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 31166.6582\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 30846.1660\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 30505.5938\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 30100.6406\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 29602.9785\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 29032.6719\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 28361.0723\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 27602.3809\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 26774.7656\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 25903.0918\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 25009.0918\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 24099.3184\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 23169.9062\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 22227.3594\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 21259.3379\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 20264.8770\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 19254.4160\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 18235.5469\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 17207.3203\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16157.7080\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 15064.7393\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 13903.3779\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 12655.1826\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11310.8584\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9864.5752\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8322.3916\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6690.3672\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4974.2871\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3324.2217\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1967.6235\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 904.3776\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 142.2042\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 115.2032\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 675.8150\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1156.1185\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1304.1669\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1148.0796\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 902.1555\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 700.6330\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 461.6623\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 253.7830\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 105.3852\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 32.3615\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.3114\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 21.4279\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 41.5666\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 65.2788\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 87.4011\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 104.7609\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 115.6395\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 119.4774\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 116.6424\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 108.1769\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 95.5691\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 80.5315\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 64.7996\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 49.9504\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 37.2577\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 27.5926\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 21.3709\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.5551\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 18.7079\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 21.0909\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 24.7965\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 28.8894\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 32.5409\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 35.1331\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 36.3167\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 36.0222\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 34.4234\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 31.8689\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 28.7984\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 25.6572\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 22.8286\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 20.5864\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.0747\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 18.3110\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 18.2063\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 18.5984\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.2885\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 20.0759\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 20.7865\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 21.2928\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 21.5226\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 21.4603\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 21.1373\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20.6215\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.9991\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 19.3595\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 18.7821\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 18.3243\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.0180\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 17.8670\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 17.8518\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 17.9360\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.0745\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18.2218\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 18.3401\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 18.4032\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 18.3992\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 18.3297\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 18.2073\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 18.0508\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 17.8807\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 17.7144\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.5618\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.4224\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.2828\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 17.1182\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.9050\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 16.6920\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.8157\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 16.5767\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.4039\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 16.3856\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 16.3477\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 16.2018\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 15.9817\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 15.8551\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 15.8244\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 15.5796\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 15.3837\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.2755\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 15.0771\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.7782\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 14.5247\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 14.2548\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 13.7903\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 13.4574\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.2448\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 13.0839\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 12.7899\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.4194\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.9570\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.5472\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 11.2136\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.8211\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 10.3689\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 9.8501\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 9.3176\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 8.7522\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.2211\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 7.7268\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 7.2656\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.8206\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.4000\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.0319\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.7340\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 5.5015\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.3145\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.1608\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.0408\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.9369\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.8544\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4.7907\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.7394\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.6991\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.6645\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.6347\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 4.6089\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.5867\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5740\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.5993\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.6936\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.8265\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.4914\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.7698\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.6251\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.6087\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.5566\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.4984\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.5103\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 4.4773\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.4288\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 4.4405\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.3810\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.4180\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.3253\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.3917\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.2966\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.3520\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.2787\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.3126\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4.2658\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.2721\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.2595\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.2360\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.2469\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.2120\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4.2283\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.1948\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.2065\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 4.1822\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 4.1829\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4.1715\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.1608\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.1586\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.1423\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.1436\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.1260\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.1271\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.1115\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4.1096\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.0977\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 4.0924\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4.0835\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 4.0758\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.0692\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 4.0597\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0544\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.0444\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.0394\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.0294\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.0243\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.0147\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0093\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.0001\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.9944\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.9857\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9797\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.9713\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.9652\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.9571\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.9508\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.9429\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.9366\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9289\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.9225\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9149\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.9085\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.9011\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.8946\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8874\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8808\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.8738\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8672\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8602\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8537\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8469\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8403\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8336\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.8269\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8204\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8138\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.8073\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.8007\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7944\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.7878\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7815\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7750\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7687\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7624\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.7561\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.7498\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.7436\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.7374\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.7312\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.7251\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7189\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7128\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.7068\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.7007\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6947\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.6887\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.6828\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6768\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6709\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.6651\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.6592\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.6534\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6476\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6419\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6361\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.6304\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.6247\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6191\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6135\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6079\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.6023\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5967\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.5913\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5858\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5803\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.5749\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.5694\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.5641\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5587\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.5534\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.5481\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5428\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.5376\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5324\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.5271\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5220\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.5169\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5118\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.5067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65e0419b50>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting for the next 10 days"
      ],
      "metadata": {
        "id": "9HUttQPSM10w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from array import array"
      ],
      "metadata": {
        "id": "D6MpUnYAOyMp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#demonstrate the prediction for the next 10 days\n",
        "\n",
        "x_input = np.array([187,196,210])\n",
        "temp_input=list(x_input)\n",
        "lst_output=[]\n",
        "i=0\n",
        "while(i<10):\n",
        "    \n",
        "    if(len(temp_input)>3):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        #print(x_input)\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.append(yhat[0][0])\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.append(yhat[0][0])\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    \n",
        "\n",
        "print(lst_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFIvQoKjNBFz",
        "outputId": "f510e641-3edf-4f01-aed0-f221c619f93d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[225.44019]\n",
            "1 day input [196.         210.         225.44018555]\n",
            "1 day output [[237.22713]]\n",
            "2 day input [210.         225.44018555 237.22712708]\n",
            "2 day output [[252.22696]]\n",
            "3 day input [225.44019 237.22713 252.22696]\n",
            "3 day output [[267.78305]]\n",
            "4 day input [237.22713 252.22696 267.78305]\n",
            "4 day output [[281.97754]]\n",
            "5 day input [252.22696 267.78305 281.97754]\n",
            "5 day output [[298.39655]]\n",
            "6 day input [267.78305 281.97754 298.39655]\n",
            "6 day output [[315.26892]]\n",
            "7 day input [281.97754 298.39655 315.26892]\n",
            "7 day output [[331.99454]]\n",
            "8 day input [298.39655 315.26892 331.99454]\n",
            "8 day output [[350.46527]]\n",
            "9 day input [315.26892 331.99454 350.46527]\n",
            "9 day output [[369.5704]]\n",
            "[225.44019, 237.22713, 252.22696, 267.78305, 281.97754, 298.39655, 315.26892, 331.99454, 350.46527, 369.5704]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRgwV1mJNcX7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeseries_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CpT7KkJTwum",
        "outputId": "b5e7b35e-425e-47b1-8a61-46b0285daba5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[110, 125, 133, 146, 158, 172, 187, 196, 210]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(timeseries_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLwcPCfcUh6O",
        "outputId": "ab121333-4a58-47d6-f437-7f9a763962b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkfj7lXVUnH6",
        "outputId": "13016ab0-63d7-4ad4-b90b-c0e10f4b10ab"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[225.44019,\n",
              " 237.22713,\n",
              " 252.22696,\n",
              " 267.78305,\n",
              " 281.97754,\n",
              " 298.39655,\n",
              " 315.26892,\n",
              " 331.99454,\n",
              " 350.46527,\n",
              " 369.5704]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualising the output"
      ],
      "metadata": {
        "id": "BT_StkbMUqmr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from array import array"
      ],
      "metadata": {
        "id": "SUerxUdCUvFg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_new = np.arange(1,10)\n",
        "day_pred = np.arange(10,20)\n"
      ],
      "metadata": {
        "id": "57CI4GcYU_nu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(day_new,timeseries_data)\n",
        "plt.plot(day_pred,lst_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oOMoum3pVO6z",
        "outputId": "9a78367e-7139-4f96-b091-a083e5af0934"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f65ed1de210>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAeZD5whnlEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}